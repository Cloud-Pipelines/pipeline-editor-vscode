apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: xgboost-pipeline
  annotations:
    cloud-pipelines.net/pipeline-editor: "true"
spec:
  entrypoint: XGBoost-pipeline
  templates:
    - name: Chicago-Taxi-Trips-dataset
      inputs:
        parameters:
          - name: Select
          - name: Where
          - name: Limit
          - name: Format
        artifacts: []
      outputs:
        parameters: []
        artifacts:
          - name: Table
            path: /tmp/outputs/Table/data
      container:
        name: main
        image: byrnedo/alpine-curl@sha256:548379d0a4a0c08b9e55d9d87a592b7d35d9ab3037f4936f5ccd09d0b625a342
        command:
          - sh
          - "-c"
          - |
            set -e -x -o pipefail
            output_path="$0"
            select="$1"
            where="$2"
            limit="$3"
            format="$4"
            mkdir -p "$(dirname "$output_path")"
            curl --get 'https://data.cityofchicago.org/resource/wrvz-psew.'"${format}" \
                --data-urlencode '$limit='"${limit}" \
                --data-urlencode '$where='"${where}" \
                --data-urlencode '$select='"${select}" \
                | tr -d '"' > "$output_path"  # Removing unneeded quotes around all numbers
          - "{{outputs.artifacts.Table.path}}"
          - "{{inputs.parameters.Select}}"
          - "{{inputs.parameters.Where}}"
          - "{{inputs.parameters.Limit}}"
          - "{{inputs.parameters.Format}}"
    - name: Split-table-into-folds
      inputs:
        parameters: []
        artifacts:
          - name: table
            path: /tmp/inputs/table/data
      outputs:
        parameters: []
        artifacts:
          - name: train_1
            path: /tmp/outputs/train_1/data
          - name: train_2
            path: /tmp/outputs/train_2/data
          - name: train_3
            path: /tmp/outputs/train_3/data
          - name: train_4
            path: /tmp/outputs/train_4/data
          - name: train_5
            path: /tmp/outputs/train_5/data
          - name: test_1
            path: /tmp/outputs/test_1/data
          - name: test_2
            path: /tmp/outputs/test_2/data
          - name: test_3
            path: /tmp/outputs/test_3/data
          - name: test_4
            path: /tmp/outputs/test_4/data
          - name: test_5
            path: /tmp/outputs/test_5/data
      container:
        name: main
        image: python:3.7
        command:
          - sh
          - "-c"
          - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.23.1' 'pandas==1.0.5' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.23.1' 'pandas==1.0.5' --user) && "$0" "$@"
          - python3
          - "-u"
          - "-c"
          - |
            def _make_parent_dirs_and_return_path(file_path: str):
                import os
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                return file_path

            def split_table_into_folds(
                table_path,

                train_1_path,
                train_2_path,
                train_3_path,
                train_4_path,
                train_5_path,

                test_1_path,
                test_2_path,
                test_3_path,
                test_4_path,
                test_5_path,

                number_of_folds = 5,
                random_seed = 0,
            ):
                """Splits the data table into the specified number of folds.

                The data is split into the specified number of folds k (default: 5).
                Each testing subsample has 1/k fraction of samples. The testing subsamples do not overlap.
                Each training subsample has (k-1)/k fraction of samples.
                The train_i subsample is produced by excluding test_i subsample form all samples.

                Inputs:
                    table: The data to split by rows
                    number_of_folds: Number of folds to split data into
                    random_seed: Random seed for reproducible splitting

                Outputs:
                    train_i: The i-th training subsample
                    test_i: The i-th testing subsample

                Annotations:
                    author: Alexey Volkov <alexey.volkov@ark-kun.com>

                """
                import pandas
                from sklearn import model_selection

                max_number_of_folds = 5

                if number_of_folds < 1 or number_of_folds > max_number_of_folds:
                    raise ValueError('Number of folds must be between 1 and {}.'.format(max_number_of_folds))

                df = pandas.read_csv(
                    table_path,
                )
                splitter = model_selection.KFold(
                    n_splits=number_of_folds,
                    shuffle=True,
                    random_state=random_seed,
                )
                folds = list(splitter.split(df))

                fold_paths = [
                    (train_1_path, test_1_path),
                    (train_2_path, test_2_path),
                    (train_3_path, test_3_path),
                    (train_4_path, test_4_path),
                    (train_5_path, test_5_path),
                ]

                for i in range(max_number_of_folds):
                    (train_path, test_path) = fold_paths[i]
                    if i < len(folds):
                        (train_indices, test_indices) = folds[i]
                        train_fold = df.iloc[train_indices]
                        test_fold = df.iloc[test_indices]
                    else:
                        train_fold = df.iloc[0:0]
                        test_fold = df.iloc[0:0]
                    train_fold.to_csv(train_path, index=False)
                    test_fold.to_csv(test_path, index=False)

            import argparse
            _parser = argparse.ArgumentParser(prog='Split table into folds', description='Splits the data table into the specified number of folds.\n\n    The data is split into the specified number of folds k (default: 5).\n    Each testing subsample has 1/k fraction of samples. The testing subsamples do not overlap.\n    Each training subsample has (k-1)/k fraction of samples.\n    The train_i subsample is produced by excluding test_i subsample form all samples.\n\n    Inputs:\n        table: The data to split by rows\n        number_of_folds: Number of folds to split data into\n        random_seed: Random seed for reproducible splitting\n\n    Outputs:\n        train_i: The i-th training subsample\n        test_i: The i-th testing subsample\n\n    Annotations:\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>')
            _parser.add_argument("--table", dest="table_path", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--number-of-folds", dest="number_of_folds", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--random-seed", dest="random_seed", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--train-1", dest="train_1_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--train-2", dest="train_2_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--train-3", dest="train_3_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--train-4", dest="train_4_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--train-5", dest="train_5_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--test-1", dest="test_1_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--test-2", dest="test_2_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--test-3", dest="test_3_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--test-4", dest="test_4_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--test-5", dest="test_5_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = split_table_into_folds(**_parsed_args)
        args:
          - "--table"
          - "{{inputs.artifacts.table.path}}"
          - "--train-1"
          - "{{outputs.artifacts.train_1.path}}"
          - "--train-2"
          - "{{outputs.artifacts.train_2.path}}"
          - "--train-3"
          - "{{outputs.artifacts.train_3.path}}"
          - "--train-4"
          - "{{outputs.artifacts.train_4.path}}"
          - "--train-5"
          - "{{outputs.artifacts.train_5.path}}"
          - "--test-1"
          - "{{outputs.artifacts.test_1.path}}"
          - "--test-2"
          - "{{outputs.artifacts.test_2.path}}"
          - "--test-3"
          - "{{outputs.artifacts.test_3.path}}"
          - "--test-4"
          - "{{outputs.artifacts.test_4.path}}"
          - "--test-5"
          - "{{outputs.artifacts.test_5.path}}"
    - name: Xgboost-train
      inputs:
        parameters:
          - name: label_column
          - name: num_iterations
          - name: objective
        artifacts:
          - name: training_data
            path: /tmp/inputs/training_data/data
      outputs:
        parameters: []
        artifacts:
          - name: model
            path: /tmp/outputs/model/data
          - name: model_config
            path: /tmp/outputs/model_config/data
      container:
        name: main
        image: python:3.7
        command:
          - sh
          - "-c"
          - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' --user) && "$0" "$@"
          - python3
          - "-u"
          - "-c"
          - |
            def _make_parent_dirs_and_return_path(file_path: str):
                import os
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                return file_path

            def xgboost_train(
                training_data_path,  # Also supports LibSVM
                model_path,
                model_config_path,
                starting_model_path = None,

                label_column = 0,
                num_iterations = 10,
                booster_params = None,

                # Booster parameters
                objective = 'reg:squarederror',
                booster = 'gbtree',
                learning_rate = 0.3,
                min_split_loss = 0,
                max_depth = 6,
            ):
                '''Train an XGBoost model.

                Args:
                    training_data_path: Path for the training data in CSV format.
                    model_path: Output path for the trained model in binary XGBoost format.
                    model_config_path: Output path for the internal parameter configuration of Booster as a JSON string.
                    starting_model_path: Path for the existing trained model to start from.
                    label_column: Column containing the label data.
                    num_boost_rounds: Number of boosting iterations.
                    booster_params: Parameters for the booster. See https://xgboost.readthedocs.io/en/latest/parameter.html
                    objective: The learning task and the corresponding learning objective.
                        See https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters
                        The most common values are:
                        "reg:squarederror" - Regression with squared loss (default).
                        "reg:logistic" - Logistic regression.
                        "binary:logistic" - Logistic regression for binary classification, output probability.
                        "binary:logitraw" - Logistic regression for binary classification, output score before logistic transformation
                        "rank:pairwise" - Use LambdaMART to perform pairwise ranking where the pairwise loss is minimized
                        "rank:ndcg" - Use LambdaMART to perform list-wise ranking where Normalized Discounted Cumulative Gain (NDCG) is maximized

                Annotations:
                    author: Alexey Volkov <alexey.volkov@ark-kun.com>
                '''
                import pandas
                import xgboost

                df = pandas.read_csv(
                    training_data_path,
                )

                training_data = xgboost.DMatrix(
                    data=df.drop(columns=[df.columns[label_column]]),
                    label=df[df.columns[label_column]],
                )

                booster_params = booster_params or {}
                booster_params.setdefault('objective', objective)
                booster_params.setdefault('booster', booster)
                booster_params.setdefault('learning_rate', learning_rate)
                booster_params.setdefault('min_split_loss', min_split_loss)
                booster_params.setdefault('max_depth', max_depth)

                starting_model = None
                if starting_model_path:
                    starting_model = xgboost.Booster(model_file=starting_model_path)

                model = xgboost.train(
                    params=booster_params,
                    dtrain=training_data,
                    num_boost_round=num_iterations,
                    xgb_model=starting_model
                )

                # Saving the model in binary format
                model.save_model(model_path)

                model_config_str = model.save_config()
                with open(model_config_path, 'w') as model_config_file:
                    model_config_file.write(model_config_str)

            import json
            import argparse
            _parser = argparse.ArgumentParser(prog='Xgboost train', description='Train an XGBoost model.\n\n    Args:\n        training_data_path: Path for the training data in CSV format.\n        model_path: Output path for the trained model in binary XGBoost format.\n        model_config_path: Output path for the internal parameter configuration of Booster as a JSON string.\n        starting_model_path: Path for the existing trained model to start from.\n        label_column: Column containing the label data.\n        num_boost_rounds: Number of boosting iterations.\n        booster_params: Parameters for the booster. See https://xgboost.readthedocs.io/en/latest/parameter.html\n        objective: The learning task and the corresponding learning objective.\n            See https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters\n            The most common values are:\n            "reg:squarederror" - Regression with squared loss (default).\n            "reg:logistic" - Logistic regression.\n            "binary:logistic" - Logistic regression for binary classification, output probability.\n            "binary:logitraw" - Logistic regression for binary classification, output score before logistic transformation\n            "rank:pairwise" - Use LambdaMART to perform pairwise ranking where the pairwise loss is minimized\n            "rank:ndcg" - Use LambdaMART to perform list-wise ranking where Normalized Discounted Cumulative Gain (NDCG) is maximized\n\n    Annotations:\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>')
            _parser.add_argument("--training-data", dest="training_data_path", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--starting-model", dest="starting_model_path", type=str, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--label-column", dest="label_column", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--num-iterations", dest="num_iterations", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--booster-params", dest="booster_params", type=json.loads, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--objective", dest="objective", type=str, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--booster", dest="booster", type=str, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--learning-rate", dest="learning_rate", type=float, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--min-split-loss", dest="min_split_loss", type=float, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--max-depth", dest="max_depth", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--model", dest="model_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--model-config", dest="model_config_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = xgboost_train(**_parsed_args)
        args:
          - "--training-data"
          - "{{inputs.artifacts.training_data.path}}"
          - "--label-column"
          - "{{inputs.parameters.label_column}}"
          - "--num-iterations"
          - "{{inputs.parameters.num_iterations}}"
          - "--objective"
          - "{{inputs.parameters.objective}}"
          - "--model"
          - "{{outputs.artifacts.model.path}}"
          - "--model-config"
          - "{{outputs.artifacts.model_config.path}}"
    - name: Convert-artifact-to-parameter
      inputs:
        artifacts:
          - name: artifact
            path: /tmp/inputs/artifact/data
      outputs:
        parameters:
          - name: parameter
            valueFrom:
              path: /tmp/inputs/parameter/data
      container:
        name: main
        image: alpine
        command:
          - sh
          - "-ec"
          - mkdir -p "$(dirname "$1")"; cp "$0" "$1"
          - "{{inputs.artifacts.artifact.path}}"
          - "{{outputs.parameters.parameter.path}}"
    - name: Xgboost-predict
      inputs:
        parameters:
          - name: label_column
        artifacts:
          - name: data
            path: /tmp/inputs/data/data
          - name: model
            path: /tmp/inputs/model/data
      outputs:
        parameters: []
        artifacts:
          - name: predictions
            path: /tmp/outputs/predictions/data
      container:
        name: main
        image: python:3.7
        command:
          - sh
          - "-c"
          - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' --user) && "$0" "$@"
          - python3
          - "-u"
          - "-c"
          - |
            def _make_parent_dirs_and_return_path(file_path: str):
                import os
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                return file_path

            def xgboost_predict(
                data_path,  # Also supports LibSVM
                model_path,
                predictions_path,
                label_column = None,
            ):
                '''Make predictions using a trained XGBoost model.

                Args:
                    data_path: Path for the feature data in CSV format.
                    model_path: Path for the trained model in binary XGBoost format.
                    predictions_path: Output path for the predictions.
                    label_column: Column containing the label data.

                Annotations:
                    author: Alexey Volkov <alexey.volkov@ark-kun.com>
                '''
                from pathlib import Path

                import numpy
                import pandas
                import xgboost

                df = pandas.read_csv(
                    data_path,
                )

                if label_column is not None:
                    df = df.drop(columns=[df.columns[label_column]])

                testing_data = xgboost.DMatrix(
                    data=df,
                )

                model = xgboost.Booster(model_file=model_path)

                predictions = model.predict(testing_data)

                Path(predictions_path).parent.mkdir(parents=True, exist_ok=True)
                numpy.savetxt(predictions_path, predictions)

            import argparse
            _parser = argparse.ArgumentParser(prog='Xgboost predict', description='Make predictions using a trained XGBoost model.\n\n    Args:\n        data_path: Path for the feature data in CSV format.\n        model_path: Path for the trained model in binary XGBoost format.\n        predictions_path: Output path for the predictions.\n        label_column: Column containing the label data.\n\n    Annotations:\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>')
            _parser.add_argument("--data", dest="data_path", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--model", dest="model_path", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--label-column", dest="label_column", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--predictions", dest="predictions_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = xgboost_predict(**_parsed_args)
        args:
          - "--data"
          - "{{inputs.artifacts.data.path}}"
          - "--model"
          - "{{inputs.artifacts.model.path}}"
          - "--label-column"
          - "{{inputs.parameters.label_column}}"
          - "--predictions"
          - "{{outputs.artifacts.predictions.path}}"
    - name: Pandas-Transform-DataFrame-in-CSV-format
      inputs:
        parameters:
          - name: transform_code
        artifacts:
          - name: table
            path: /tmp/inputs/table/data
      outputs:
        parameters: []
        artifacts:
          - name: transformed_table
            path: /tmp/outputs/transformed_table/data
      container:
        name: main
        image: python:3.7
        command:
          - sh
          - "-c"
          - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'pandas==1.0.4' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'pandas==1.0.4' --user) && "$0" "$@"
          - python3
          - "-u"
          - "-c"
          - |
            def _make_parent_dirs_and_return_path(file_path: str):
                import os
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                return file_path

            def Pandas_Transform_DataFrame_in_CSV_format(
                table_path,
                transformed_table_path,
                transform_code,
            ):
                '''Transform DataFrame loaded from a CSV file.

                Inputs:
                    table: Table to transform.
                    transform_code: Transformation code. Code is written in Python and can consist of multiple lines.
                        The DataFrame variable is called "df".
                        Examples:
                        - `df['prod'] = df['X'] * df['Y']`
                        - `df = df[['X', 'prod']]`
                        - `df.insert(0, "is_positive", df["X"] > 0)`

                Outputs:
                    transformed_table: Transformed table.

                Annotations:
                    author: Alexey Volkov <alexey.volkov@ark-kun.com>
                '''
                import pandas

                df = pandas.read_csv(
                    table_path,
                )
                # The namespace is needed so that the code can replace `df`. For example df = df[['X']]
                namespace = locals()
                exec(transform_code, namespace)
                namespace['df'].to_csv(
                    transformed_table_path,
                    index=False,
                )

            import argparse
            _parser = argparse.ArgumentParser(prog='Pandas Transform DataFrame in CSV format', description='Transform DataFrame loaded from a CSV file.\n\n    Inputs:\n        table: Table to transform.\n        transform_code: Transformation code. Code is written in Python and can consist of multiple lines.\n            The DataFrame variable is called "df".\n            Examples:\n            - `df[\'prod\'] = df[\'X\'] * df[\'Y\']`\n            - `df = df[[\'X\', \'prod\']]`\n            - `df.insert(0, "is_positive", df["X"] > 0)`\n\n    Outputs:\n        transformed_table: Transformed table.\n\n    Annotations:\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>')
            _parser.add_argument("--table", dest="table_path", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--transform-code", dest="transform_code", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--transformed-table", dest="transformed_table_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = Pandas_Transform_DataFrame_in_CSV_format(**_parsed_args)
        args:
          - "--table"
          - "{{inputs.artifacts.table.path}}"
          - "--transform-code"
          - "{{inputs.parameters.transform_code}}"
          - "--transformed-table"
          - "{{outputs.artifacts.transformed_table.path}}"
    - name: Remove-header
      inputs:
        parameters: []
        artifacts:
          - name: table
            path: /tmp/inputs/table/data
      outputs:
        parameters: []
        artifacts:
          - name: table
            path: /tmp/outputs/table/data
      container:
        name: main
        image: alpine
        command:
          - sh
          - "-exc"
          - |
            mkdir -p "$(dirname "$1")"
            tail -n +2 <"$0" >"$1"
          - "{{inputs.artifacts.table.path}}"
          - "{{outputs.artifacts.table.path}}"
    - name: Calculate-regression-metrics-from-csv
      inputs:
        parameters: []
        artifacts:
          - name: true_values
            path: /tmp/inputs/true_values/data
          - name: predicted_values
            path: /tmp/inputs/predicted_values/data
      outputs:
        parameters: []
        artifacts:
          - name: number_of_items
            path: /tmp/outputs/number_of_items/data
          - name: max_absolute_error
            path: /tmp/outputs/max_absolute_error/data
          - name: mean_absolute_error
            path: /tmp/outputs/mean_absolute_error/data
          - name: mean_squared_error
            path: /tmp/outputs/mean_squared_error/data
          - name: root_mean_squared_error
            path: /tmp/outputs/root_mean_squared_error/data
          - name: metrics
            path: /tmp/outputs/metrics/data
      container:
        name: main
        image: python:3.7
        command:
          - sh
          - "-c"
          - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'numpy==1.19.0' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'numpy==1.19.0' --user) && "$0" "$@"
          - python3
          - "-u"
          - "-c"
          - |
            def calculate_regression_metrics_from_csv(
                true_values_path,
                predicted_values_path,
            ):
                '''Calculates regression metrics.

                Annotations:
                    author: Alexey Volkov <alexey.volkov@ark-kun.com>
                '''
                import math
                import numpy

                true_values = numpy.loadtxt(true_values_path, dtype=numpy.float64)
                predicted_values = numpy.loadtxt(predicted_values_path, dtype=numpy.float64)

                if len(predicted_values.shape) != 1:
                    raise NotImplemented('Only single prediction values are supported.')
                if len(true_values.shape) != 1:
                    raise NotImplemented('Only single true values are supported.')

                if predicted_values.shape != true_values.shape:
                    raise ValueError('Input shapes are different: {} != {}'.format(predicted_values.shape, true_values.shape))

                number_of_items = true_values.size
                errors = (true_values - predicted_values)
                abs_errors = numpy.abs(errors)
                squared_errors = errors ** 2
                max_absolute_error = numpy.max(abs_errors)
                mean_absolute_error = numpy.average(abs_errors)
                mean_squared_error = numpy.average(squared_errors)
                root_mean_squared_error = math.sqrt(mean_squared_error)
                metrics = dict(
                    number_of_items=number_of_items,
                    max_absolute_error=max_absolute_error,
                    mean_absolute_error=mean_absolute_error,
                    mean_squared_error=mean_squared_error,
                    root_mean_squared_error=root_mean_squared_error,
                )

                return (
                    number_of_items,
                    max_absolute_error,
                    mean_absolute_error,
                    mean_squared_error,
                    root_mean_squared_error,
                    metrics,
                )

            def _serialize_json(obj) -> str:
                if isinstance(obj, str):
                    return obj
                import json
                def default_serializer(obj):
                    if hasattr(obj, 'to_struct'):
                        return obj.to_struct()
                    else:
                        raise TypeError("Object of type '%s' is not JSON serializable and does not have .to_struct() method." % obj.__class__.__name__)
                return json.dumps(obj, default=default_serializer, sort_keys=True)

            def _serialize_float(float_value: float) -> str:
                if isinstance(float_value, str):
                    return float_value
                if not isinstance(float_value, (float, int)):
                    raise TypeError('Value "{}" has type "{}" instead of float.'.format(str(float_value), str(type(float_value))))
                return str(float_value)

            def _serialize_int(int_value: int) -> str:
                if isinstance(int_value, str):
                    return int_value
                if not isinstance(int_value, int):
                    raise TypeError('Value "{}" has type "{}" instead of int.'.format(str(int_value), str(type(int_value))))
                return str(int_value)

            import argparse
            _parser = argparse.ArgumentParser(prog='Calculate regression metrics from csv', description='Calculates regression metrics.\n\n    Annotations:\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>')
            _parser.add_argument("--true-values", dest="true_values_path", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--predicted-values", dest="predicted_values_path", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=6)
            _parsed_args = vars(_parser.parse_args())
            _output_files = _parsed_args.pop("_output_paths", [])

            _outputs = calculate_regression_metrics_from_csv(**_parsed_args)

            _output_serializers = [
                _serialize_int,
                _serialize_float,
                _serialize_float,
                _serialize_float,
                _serialize_float,
                _serialize_json,

            ]

            import os
            for idx, output_file in enumerate(_output_files):
                try:
                    os.makedirs(os.path.dirname(output_file))
                except OSError:
                    pass
                with open(output_file, 'w') as f:
                    f.write(_output_serializers[idx](_outputs[idx]))
        args:
          - "--true-values"
          - "{{inputs.artifacts.true_values.path}}"
          - "--predicted-values"
          - "{{inputs.artifacts.predicted_values.path}}"
          - "----output-paths"
          - "{{outputs.artifacts.number_of_items.path}}"
          - "{{outputs.artifacts.max_absolute_error.path}}"
          - "{{outputs.artifacts.mean_absolute_error.path}}"
          - "{{outputs.artifacts.mean_squared_error.path}}"
          - "{{outputs.artifacts.root_mean_squared_error.path}}"
          - "{{outputs.artifacts.metrics.path}}"
    - name: Aggregate-regression-metrics-from-csv
      inputs:
        parameters:
          - name: metrics_1
          - name: metrics_2
          - name: metrics_3
          - name: metrics_4
          - name: metrics_5
        artifacts: []
      outputs:
        parameters: []
        artifacts:
          - name: number_of_items
            path: /tmp/outputs/number_of_items/data
          - name: max_absolute_error
            path: /tmp/outputs/max_absolute_error/data
          - name: mean_absolute_error
            path: /tmp/outputs/mean_absolute_error/data
          - name: mean_squared_error
            path: /tmp/outputs/mean_squared_error/data
          - name: root_mean_squared_error
            path: /tmp/outputs/root_mean_squared_error/data
          - name: metrics
            path: /tmp/outputs/metrics/data
      container:
        name: main
        image: python:3.7
        command:
          - python3
          - "-u"
          - "-c"
          - |
            def aggregate_regression_metrics_from_csv(
                metrics_1,
                metrics_2 = None,
                metrics_3 = None,
                metrics_4 = None,
                metrics_5 = None,
            ):
                '''Calculates regression metrics.

                Annotations:
                    author: Alexey Volkov <alexey.volkov@ark-kun.com>
                '''
                import math

                metrics_dicts = [d for d in [metrics_1, metrics_2, metrics_3, metrics_4, metrics_5] if d is not None]
                number_of_items = sum(metrics['number_of_items'] for metrics in metrics_dicts)
                max_absolute_error = max(metrics['max_absolute_error'] for metrics in metrics_dicts)
                mean_absolute_error = sum(metrics['mean_absolute_error'] * metrics['number_of_items'] for metrics in metrics_dicts) / number_of_items
                mean_squared_error = sum(metrics['mean_squared_error'] * metrics['number_of_items'] for metrics in metrics_dicts) / number_of_items
                root_mean_squared_error = math.sqrt(mean_squared_error)
                metrics = dict(
                    number_of_items=number_of_items,
                    max_absolute_error=max_absolute_error,
                    mean_absolute_error=mean_absolute_error,
                    mean_squared_error=mean_squared_error,
                    root_mean_squared_error=root_mean_squared_error,
                )

                return (
                    number_of_items,
                    max_absolute_error,
                    mean_absolute_error,
                    mean_squared_error,
                    root_mean_squared_error,
                    metrics,
                )

            def _serialize_json(obj) -> str:
                if isinstance(obj, str):
                    return obj
                import json
                def default_serializer(obj):
                    if hasattr(obj, 'to_struct'):
                        return obj.to_struct()
                    else:
                        raise TypeError("Object of type '%s' is not JSON serializable and does not have .to_struct() method." % obj.__class__.__name__)
                return json.dumps(obj, default=default_serializer, sort_keys=True)

            def _serialize_float(float_value: float) -> str:
                if isinstance(float_value, str):
                    return float_value
                if not isinstance(float_value, (float, int)):
                    raise TypeError('Value "{}" has type "{}" instead of float.'.format(str(float_value), str(type(float_value))))
                return str(float_value)

            def _serialize_int(int_value: int) -> str:
                if isinstance(int_value, str):
                    return int_value
                if not isinstance(int_value, int):
                    raise TypeError('Value "{}" has type "{}" instead of int.'.format(str(int_value), str(type(int_value))))
                return str(int_value)

            import json
            import argparse
            _parser = argparse.ArgumentParser(prog='Aggregate regression metrics from csv', description='Calculates regression metrics.\n\n    Annotations:\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>')
            _parser.add_argument("--metrics-1", dest="metrics_1", type=json.loads, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--metrics-2", dest="metrics_2", type=json.loads, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--metrics-3", dest="metrics_3", type=json.loads, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--metrics-4", dest="metrics_4", type=json.loads, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--metrics-5", dest="metrics_5", type=json.loads, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=6)
            _parsed_args = vars(_parser.parse_args())
            _output_files = _parsed_args.pop("_output_paths", [])

            _outputs = aggregate_regression_metrics_from_csv(**_parsed_args)

            _output_serializers = [
                _serialize_int,
                _serialize_float,
                _serialize_float,
                _serialize_float,
                _serialize_float,
                _serialize_json,

            ]

            import os
            for idx, output_file in enumerate(_output_files):
                try:
                    os.makedirs(os.path.dirname(output_file))
                except OSError:
                    pass
                with open(output_file, 'w') as f:
                    f.write(_output_serializers[idx](_outputs[idx]))
        args:
          - "--metrics-1"
          - "{{inputs.parameters.metrics_1}}"
          - "--metrics-2"
          - "{{inputs.parameters.metrics_2}}"
          - "--metrics-3"
          - "{{inputs.parameters.metrics_3}}"
          - "--metrics-4"
          - "{{inputs.parameters.metrics_4}}"
          - "--metrics-5"
          - "{{inputs.parameters.metrics_5}}"
          - "----output-paths"
          - "{{outputs.artifacts.number_of_items.path}}"
          - "{{outputs.artifacts.max_absolute_error.path}}"
          - "{{outputs.artifacts.mean_absolute_error.path}}"
          - "{{outputs.artifacts.mean_squared_error.path}}"
          - "{{outputs.artifacts.root_mean_squared_error.path}}"
          - "{{outputs.artifacts.metrics.path}}"
    - name: Xgboost-5-fold-cross-validation-for-regression
      inputs:
        parameters: []
        artifacts:
          - name: data
      outputs:
        artifacts:
          - name: mean_absolute_error
            from: "{{tasks.Aggregate-regression-metrics-from-csv.outputs.artifacts.mean_absolute_error}}"
          - name: mean_squared_error
            from: "{{tasks.Aggregate-regression-metrics-from-csv.outputs.artifacts.mean_squared_error}}"
          - name: root_mean_squared_error
            from: "{{tasks.Aggregate-regression-metrics-from-csv.outputs.artifacts.root_mean_squared_error}}"
          - name: metrics
            from: "{{tasks.Aggregate-regression-metrics-from-csv.outputs.artifacts.metrics}}"
      dag:
        tasks:
          - name: Split-table-into-folds
            template: Split-table-into-folds
            arguments:
              parameters: []
              artifacts:
                - name: table
                  from: "{{inputs.artifacts.data}}"
            dependencies: []
          - name: Make-parameter-for-label-column
            template: Convert-artifact-to-parameter
            arguments:
              artifacts:
                - name: artifact
                  from: "{{inputs.artifacts.label_column}}"
          - name: Make-parameter-for-num-iterations
            template: Convert-artifact-to-parameter
            arguments:
              artifacts:
                - name: artifact
                  from: "{{inputs.artifacts.num_iterations}}"
          - name: Make-parameter-for-objective
            template: Convert-artifact-to-parameter
            arguments:
              artifacts:
                - name: artifact
                  from: "{{inputs.artifacts.objective}}"
          - name: Xgboost-train
            template: Xgboost-train
            arguments:
              parameters:
                - name: label_column
                  value: "{{tasks.Make-parameter-for-label-column.outputs.parameters.parameter}}"
                - name: num_iterations
                  value: "{{tasks.Make-parameter-for-num-iterations.outputs.parameters.parameter}}"
                - name: objective
                  value: "{{tasks.Make-parameter-for-objective.outputs.parameters.parameter}}"
              artifacts:
                - name: training_data
                  from: "{{tasks.Split-table-into-folds.outputs.artifacts.train_1}}"
            dependencies:
              - Make-parameter-for-label-column
              - Make-parameter-for-num-iterations
              - Make-parameter-for-objective
              - Split-table-into-folds
          - name: Xgboost-predict
            template: Xgboost-predict
            arguments:
              parameters:
                - name: label_column
                  value: "{{tasks.Make-parameter-for-label-column.outputs.parameters.parameter}}"
              artifacts:
                - name: data
                  from: "{{tasks.Split-table-into-folds.outputs.artifacts.test_1}}"
                - name: model
                  from: "{{tasks.Xgboost-train.outputs.artifacts.model}}"
            dependencies:
              - Make-parameter-for-label-column
              - Split-table-into-folds
              - Xgboost-train
          - name: Pandas-Transform-DataFrame-in-CSV-format
            template: Pandas-Transform-DataFrame-in-CSV-format
            arguments:
              parameters:
                - name: transform_code
                  value: df = df[["tips"]]
              artifacts:
                - name: table
                  from: "{{tasks.Split-table-into-folds.outputs.artifacts.test_1}}"
            dependencies:
              - Split-table-into-folds
          - name: Remove-header
            template: Remove-header
            arguments:
              parameters: []
              artifacts:
                - name: table
                  from: "{{tasks.Pandas-Transform-DataFrame-in-CSV-format.outputs.artifacts.transformed_table}}"
            dependencies:
              - Pandas-Transform-DataFrame-in-CSV-format
          - name: Calculate-regression-metrics-from-csv
            template: Calculate-regression-metrics-from-csv
            arguments:
              parameters: []
              artifacts:
                - name: true_values
                  from: "{{tasks.Remove-header.outputs.artifacts.table}}"
                - name: predicted_values
                  from: "{{tasks.Xgboost-predict.outputs.artifacts.predictions}}"
            dependencies:
              - Remove-header
              - Xgboost-predict
          - name: Xgboost-train-2
            template: Xgboost-train
            arguments:
              parameters:
                - name: label_column
                  value: "{{tasks.Make-parameter-for-label-column.outputs.parameters.parameter}}"
                - name: num_iterations
                  value: "{{tasks.Make-parameter-for-num-iterations.outputs.parameters.parameter}}"
                - name: objective
                  value: "{{tasks.Make-parameter-for-objective.outputs.parameters.parameter}}"
              artifacts:
                - name: training_data
                  from: "{{tasks.Split-table-into-folds.outputs.artifacts.train_2}}"
            dependencies:
              - Make-parameter-for-label-column
              - Make-parameter-for-num-iterations
              - Make-parameter-for-objective
              - Split-table-into-folds
          - name: Xgboost-predict-2
            template: Xgboost-predict
            arguments:
              parameters:
                - name: label_column
                  value: "{{tasks.Make-parameter-for-label-column.outputs.parameters.parameter}}"
              artifacts:
                - name: data
                  from: "{{tasks.Split-table-into-folds.outputs.artifacts.test_2}}"
                - name: model
                  from: "{{tasks.Xgboost-train-2.outputs.artifacts.model}}"
            dependencies:
              - Make-parameter-for-label-column
              - Split-table-into-folds
              - Xgboost-train-2
          - name: Pandas-Transform-DataFrame-in-CSV-format-2
            template: Pandas-Transform-DataFrame-in-CSV-format
            arguments:
              parameters:
                - name: transform_code
                  value: df = df[["tips"]]
              artifacts:
                - name: table
                  from: "{{tasks.Split-table-into-folds.outputs.artifacts.test_2}}"
            dependencies:
              - Split-table-into-folds
          - name: Remove-header-2
            template: Remove-header
            arguments:
              parameters: []
              artifacts:
                - name: table
                  from: "{{tasks.Pandas-Transform-DataFrame-in-CSV-format-2.outputs.artifacts.transformed_table}}"
            dependencies:
              - Pandas-Transform-DataFrame-in-CSV-format-2
          - name: Calculate-regression-metrics-from-csv-2
            template: Calculate-regression-metrics-from-csv
            arguments:
              parameters: []
              artifacts:
                - name: true_values
                  from: "{{tasks.Remove-header-2.outputs.artifacts.table}}"
                - name: predicted_values
                  from: "{{tasks.Xgboost-predict-2.outputs.artifacts.predictions}}"
            dependencies:
              - Remove-header-2
              - Xgboost-predict-2
          - name: Xgboost-train-3
            template: Xgboost-train
            arguments:
              parameters:
                - name: label_column
                  value: "{{tasks.Make-parameter-for-label-column.outputs.parameters.parameter}}"
                - name: num_iterations
                  value: "{{tasks.Make-parameter-for-num-iterations.outputs.parameters.parameter}}"
                - name: objective
                  value: "{{tasks.Make-parameter-for-objective.outputs.parameters.parameter}}"
              artifacts:
                - name: training_data
                  from: "{{tasks.Split-table-into-folds.outputs.artifacts.train_3}}"
            dependencies:
              - Make-parameter-for-label-column
              - Make-parameter-for-num-iterations
              - Make-parameter-for-objective
              - Split-table-into-folds
          - name: Xgboost-predict-3
            template: Xgboost-predict
            arguments:
              parameters:
                - name: label_column
                  value: "{{tasks.Make-parameter-for-label-column.outputs.parameters.parameter}}"
              artifacts:
                - name: data
                  from: "{{tasks.Split-table-into-folds.outputs.artifacts.test_3}}"
                - name: model
                  from: "{{tasks.Xgboost-train-3.outputs.artifacts.model}}"
            dependencies:
              - Make-parameter-for-label-column
              - Split-table-into-folds
              - Xgboost-train-3
          - name: Pandas-Transform-DataFrame-in-CSV-format-3
            template: Pandas-Transform-DataFrame-in-CSV-format
            arguments:
              parameters:
                - name: transform_code
                  value: df = df[["tips"]]
              artifacts:
                - name: table
                  from: "{{tasks.Split-table-into-folds.outputs.artifacts.test_3}}"
            dependencies:
              - Split-table-into-folds
          - name: Remove-header-3
            template: Remove-header
            arguments:
              parameters: []
              artifacts:
                - name: table
                  from: "{{tasks.Pandas-Transform-DataFrame-in-CSV-format-3.outputs.artifacts.transformed_table}}"
            dependencies:
              - Pandas-Transform-DataFrame-in-CSV-format-3
          - name: Calculate-regression-metrics-from-csv-3
            template: Calculate-regression-metrics-from-csv
            arguments:
              parameters: []
              artifacts:
                - name: true_values
                  from: "{{tasks.Remove-header-3.outputs.artifacts.table}}"
                - name: predicted_values
                  from: "{{tasks.Xgboost-predict-3.outputs.artifacts.predictions}}"
            dependencies:
              - Remove-header-3
              - Xgboost-predict-3
          - name: Xgboost-train-4
            template: Xgboost-train
            arguments:
              parameters:
                - name: label_column
                  value: "{{tasks.Make-parameter-for-label-column.outputs.parameters.parameter}}"
                - name: num_iterations
                  value: "{{tasks.Make-parameter-for-num-iterations.outputs.parameters.parameter}}"
                - name: objective
                  value: "{{tasks.Make-parameter-for-objective.outputs.parameters.parameter}}"
              artifacts:
                - name: training_data
                  from: "{{tasks.Split-table-into-folds.outputs.artifacts.train_4}}"
            dependencies:
              - Make-parameter-for-label-column
              - Make-parameter-for-num-iterations
              - Make-parameter-for-objective
              - Split-table-into-folds
          - name: Xgboost-predict-4
            template: Xgboost-predict
            arguments:
              parameters:
                - name: label_column
                  value: "{{tasks.Make-parameter-for-label-column.outputs.parameters.parameter}}"
              artifacts:
                - name: data
                  from: "{{tasks.Split-table-into-folds.outputs.artifacts.test_4}}"
                - name: model
                  from: "{{tasks.Xgboost-train-4.outputs.artifacts.model}}"
            dependencies:
              - Make-parameter-for-label-column
              - Split-table-into-folds
              - Xgboost-train-4
          - name: Pandas-Transform-DataFrame-in-CSV-format-4
            template: Pandas-Transform-DataFrame-in-CSV-format
            arguments:
              parameters:
                - name: transform_code
                  value: df = df[["tips"]]
              artifacts:
                - name: table
                  from: "{{tasks.Split-table-into-folds.outputs.artifacts.test_4}}"
            dependencies:
              - Split-table-into-folds
          - name: Remove-header-4
            template: Remove-header
            arguments:
              parameters: []
              artifacts:
                - name: table
                  from: "{{tasks.Pandas-Transform-DataFrame-in-CSV-format-4.outputs.artifacts.transformed_table}}"
            dependencies:
              - Pandas-Transform-DataFrame-in-CSV-format-4
          - name: Calculate-regression-metrics-from-csv-4
            template: Calculate-regression-metrics-from-csv
            arguments:
              parameters: []
              artifacts:
                - name: true_values
                  from: "{{tasks.Remove-header-4.outputs.artifacts.table}}"
                - name: predicted_values
                  from: "{{tasks.Xgboost-predict-4.outputs.artifacts.predictions}}"
            dependencies:
              - Remove-header-4
              - Xgboost-predict-4
          - name: Xgboost-train-5
            template: Xgboost-train
            arguments:
              parameters:
                - name: label_column
                  value: "{{tasks.Make-parameter-for-label-column.outputs.parameters.parameter}}"
                - name: num_iterations
                  value: "{{tasks.Make-parameter-for-num-iterations.outputs.parameters.parameter}}"
                - name: objective
                  value: "{{tasks.Make-parameter-for-objective.outputs.parameters.parameter}}"
              artifacts:
                - name: training_data
                  from: "{{tasks.Split-table-into-folds.outputs.artifacts.train_5}}"
            dependencies:
              - Make-parameter-for-label-column
              - Make-parameter-for-num-iterations
              - Make-parameter-for-objective
              - Split-table-into-folds
          - name: Xgboost-predict-5
            template: Xgboost-predict
            arguments:
              parameters:
                - name: label_column
                  value: "{{tasks.Make-parameter-for-label-column.outputs.parameters.parameter}}"
              artifacts:
                - name: data
                  from: "{{tasks.Split-table-into-folds.outputs.artifacts.test_5}}"
                - name: model
                  from: "{{tasks.Xgboost-train-5.outputs.artifacts.model}}"
            dependencies:
              - Make-parameter-for-label-column
              - Split-table-into-folds
              - Xgboost-train-5
          - name: Pandas-Transform-DataFrame-in-CSV-format-5
            template: Pandas-Transform-DataFrame-in-CSV-format
            arguments:
              parameters:
                - name: transform_code
                  value: df = df[["tips"]]
              artifacts:
                - name: table
                  from: "{{tasks.Split-table-into-folds.outputs.artifacts.test_5}}"
            dependencies:
              - Split-table-into-folds
          - name: Remove-header-5
            template: Remove-header
            arguments:
              parameters: []
              artifacts:
                - name: table
                  from: "{{tasks.Pandas-Transform-DataFrame-in-CSV-format-5.outputs.artifacts.transformed_table}}"
            dependencies:
              - Pandas-Transform-DataFrame-in-CSV-format-5
          - name: Calculate-regression-metrics-from-csv-5
            template: Calculate-regression-metrics-from-csv
            arguments:
              parameters: []
              artifacts:
                - name: true_values
                  from: "{{tasks.Remove-header-5.outputs.artifacts.table}}"
                - name: predicted_values
                  from: "{{tasks.Xgboost-predict-5.outputs.artifacts.predictions}}"
            dependencies:
              - Remove-header-5
              - Xgboost-predict-5
          - name: Make-parameter-for-Calculate-regression-metrics-from-csv-output-metrics
            template: Convert-artifact-to-parameter
            arguments:
              artifacts:
                - name: artifact
                  from: "{{tasks.Calculate-regression-metrics-from-csv.outputs.artifacts.metrics}}"
            dependencies:
              - Calculate-regression-metrics-from-csv
          - name: Make-parameter-for-Calculate-regression-metrics-from-csv-2-output-metrics
            template: Convert-artifact-to-parameter
            arguments:
              artifacts:
                - name: artifact
                  from: "{{tasks.Calculate-regression-metrics-from-csv-2.outputs.artifacts.metrics}}"
            dependencies:
              - Calculate-regression-metrics-from-csv-2
          - name: Make-parameter-for-Calculate-regression-metrics-from-csv-3-output-metrics
            template: Convert-artifact-to-parameter
            arguments:
              artifacts:
                - name: artifact
                  from: "{{tasks.Calculate-regression-metrics-from-csv-3.outputs.artifacts.metrics}}"
            dependencies:
              - Calculate-regression-metrics-from-csv-3
          - name: Make-parameter-for-Calculate-regression-metrics-from-csv-4-output-metrics
            template: Convert-artifact-to-parameter
            arguments:
              artifacts:
                - name: artifact
                  from: "{{tasks.Calculate-regression-metrics-from-csv-4.outputs.artifacts.metrics}}"
            dependencies:
              - Calculate-regression-metrics-from-csv-4
          - name: Make-parameter-for-Calculate-regression-metrics-from-csv-5-output-metrics
            template: Convert-artifact-to-parameter
            arguments:
              artifacts:
                - name: artifact
                  from: "{{tasks.Calculate-regression-metrics-from-csv-5.outputs.artifacts.metrics}}"
            dependencies:
              - Calculate-regression-metrics-from-csv-5
          - name: Aggregate-regression-metrics-from-csv
            template: Aggregate-regression-metrics-from-csv
            arguments:
              parameters:
                - name: metrics_1
                  value: "{{tasks.Make-parameter-for-Calculate-regression-metrics-from-csv-output-metrics.outputs.parameters.parameter}}"
                - name: metrics_2
                  value: "{{tasks.Make-parameter-for-Calculate-regression-metrics-from-csv-2-output-metrics.outputs.parameters.parameter}}"
                - name: metrics_3
                  value: "{{tasks.Make-parameter-for-Calculate-regression-metrics-from-csv-3-output-metrics.outputs.parameters.parameter}}"
                - name: metrics_4
                  value: "{{tasks.Make-parameter-for-Calculate-regression-metrics-from-csv-4-output-metrics.outputs.parameters.parameter}}"
                - name: metrics_5
                  value: "{{tasks.Make-parameter-for-Calculate-regression-metrics-from-csv-5-output-metrics.outputs.parameters.parameter}}"
              artifacts: []
            dependencies:
              - Make-parameter-for-Calculate-regression-metrics-from-csv-2-output-metrics
              - Make-parameter-for-Calculate-regression-metrics-from-csv-3-output-metrics
              - Make-parameter-for-Calculate-regression-metrics-from-csv-4-output-metrics
              - Make-parameter-for-Calculate-regression-metrics-from-csv-5-output-metrics
              - Make-parameter-for-Calculate-regression-metrics-from-csv-output-metrics
    - name: XGBoost-pipeline
      inputs:
        parameters: []
        artifacts: []
      outputs:
        artifacts: []
      dag:
        tasks:
          - name: dataset
            template: Chicago-Taxi-Trips-dataset
            arguments:
              parameters:
                - name: Select
                  value: tips,trip_seconds,trip_miles,pickup_community_area,dropoff_community_area,fare,tolls,extras,trip_total
                - name: Where
                  value: trip_start_timestamp >= "2019-01-01" AND trip_start_timestamp < "2019-02-01"
                - name: Limit
                  value: "1000"
                - name: Format
                  value: csv
              artifacts: []
            dependencies: []
          - name: Xgboost-5-fold-cross-validation-for-regression
            template: Xgboost-5-fold-cross-validation-for-regression
            arguments:
              parameters: []
              artifacts:
                - name: data
                  from: "{{tasks.dataset.outputs.artifacts.Table}}"
            dependencies:
              - dataset
  arguments:
    parameters: []
    artifacts: []
